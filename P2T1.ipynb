{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDLY+De+boB4+G3D3mdL0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptl-harsh/QLab_Task/blob/main/P2T1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image Restoration:"
      ],
      "metadata": {
        "id": "OcI9aWkGeRZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Denoising using DNCNN architecture"
      ],
      "metadata": {
        "id": "oTeFdhPcea_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZYRsp-_OcF4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a2853c-b259-4198-df8c-e8daa8210038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.13)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Step 1: Mount Google Drive and Install Required Libraries\n",
        "# Mount Google Drive to access the CBSD68 folder.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio scikit-image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2: Import Libraries and Set Up Environment\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from PIL import Image\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n"
      ],
      "metadata": {
        "id": "QyIB0LDfehTh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3 (Modified): Define the Dataset for CBSD68 with Consistent Image Sizes\n",
        "\n",
        "# Update the base_dir variable with the correct path to your CBSD68 folder on Google Drive.\n",
        "base_dir = \"/content/drive/MyDrive/IISC_intern_task/CBSD68\"\n",
        "\n",
        "# Use \"noisy35\" for noisy images and \"original_png\" for clean images.\n",
        "noisy_dir = os.path.join(base_dir, \"noisy35\")\n",
        "clean_dir = os.path.join(base_dir, \"original_png\")\n",
        "\n",
        "# Create a custom PyTorch Dataset to load paired images.\n",
        "class CBSD68Dataset(Dataset):\n",
        "    def __init__(self, noisy_dir, clean_dir, transform=None):\n",
        "        \"\"\"\n",
        "        noisy_dir: Directory with noisy images.\n",
        "        clean_dir: Directory with ground truth images (PNG).\n",
        "        transform: Optional transforms (e.g., resizing, tensor conversion).\n",
        "        \"\"\"\n",
        "        self.noisy_paths = sorted(glob.glob(os.path.join(noisy_dir, \"*.png\")))\n",
        "        self.clean_paths = sorted(glob.glob(os.path.join(clean_dir, \"*.png\")))\n",
        "        self.transform = transform\n",
        "\n",
        "        if len(self.noisy_paths) == 0 or len(self.clean_paths) == 0:\n",
        "            raise ValueError(\"No images found. Check your directory paths and file extensions.\")\n",
        "        if len(self.noisy_paths) != len(self.clean_paths):\n",
        "            raise ValueError(\"Mismatch in number of noisy and clean images.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Open the image files using PIL\n",
        "        noisy_img = Image.open(self.noisy_paths[idx]).convert(\"RGB\")\n",
        "        clean_img = Image.open(self.clean_paths[idx]).convert(\"RGB\")\n",
        "\n",
        "        # Apply transforms if provided; otherwise, convert to tensor in [0,1] range.\n",
        "        if self.transform:\n",
        "            noisy = self.transform(noisy_img)\n",
        "            clean = self.transform(clean_img)\n",
        "        else:\n",
        "            to_tensor = transforms.ToTensor()\n",
        "            noisy = to_tensor(noisy_img)\n",
        "            clean = to_tensor(clean_img)\n",
        "\n",
        "        return noisy, clean\n",
        "\n",
        "# Define a transform that resizes all images to a fixed size and then converts them to tensor.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize images to 256x256 (adjust as needed)\n",
        "    transforms.ToTensor(),          # Convert image to tensor with pixel values in [0,1]\n",
        "])\n",
        "\n",
        "# Create the dataset instance\n",
        "dataset = CBSD68Dataset(noisy_dir, clean_dir, transform=transform)\n",
        "print(\"Number of image pairs:\", len(dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNF2WLf8is3G",
        "outputId": "053303ca-f4a9-472e-effb-57493bf9f329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of image pairs: 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 4: Define the DnCNN Model for Image Denoising\n",
        "# DnCNN uses residual learning to predict the noise; the denoised image is obtained by subtracting the predicted noise from the input.\n",
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, channels=3, num_of_layers=17, num_of_features=64):\n",
        "        super(DnCNN, self).__init__()\n",
        "        kernel_size = 3\n",
        "        padding = 1  # To preserve image size\n",
        "\n",
        "        # First layer: Convolution + ReLU (no BatchNorm)\n",
        "        layers = [nn.Conv2d(channels, num_of_features, kernel_size, padding=padding),\n",
        "                  nn.ReLU(inplace=True)]\n",
        "\n",
        "        # Intermediate layers: Convolution + BatchNorm + ReLU\n",
        "        for _ in range(num_of_layers - 2):\n",
        "            layers += [nn.Conv2d(num_of_features, num_of_features, kernel_size, padding=padding),\n",
        "                       nn.BatchNorm2d(num_of_features),\n",
        "                       nn.ReLU(inplace=True)]\n",
        "\n",
        "        # Last layer: Convolution (output noise)\n",
        "        layers.append(nn.Conv2d(num_of_features, channels, kernel_size, padding=padding))\n",
        "\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise = self.dncnn(x)\n",
        "        # Residual learning: subtract predicted noise from input image\n",
        "        return x - noise\n",
        "\n",
        "# Initialize the model\n",
        "model = DnCNN(channels=3, num_of_layers=17, num_of_features=64)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT72u0jhi8NZ",
        "outputId": "76da2e6c-d4e5-4a38-9630-80f49b11b1bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DnCNN(\n",
            "  (dncnn): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (28): ReLU(inplace=True)\n",
            "    (29): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (30): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (34): ReLU(inplace=True)\n",
            "    (35): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (36): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (37): ReLU(inplace=True)\n",
            "    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (40): ReLU(inplace=True)\n",
            "    (41): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (42): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (43): ReLU(inplace=True)\n",
            "    (44): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (46): ReLU(inplace=True)\n",
            "    (47): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 5: Set Up Training Parameters and DataLoader\n",
        "# Hyperparameters\n",
        "num_epochs = 15\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Create DataLoader for the dataset\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "dmjOXqOwlNIN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 6: Train the DnCNN Model\n",
        "model.train()\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    for i, (noisy_imgs, clean_imgs) in enumerate(dataloader):\n",
        "        noisy_imgs = noisy_imgs.to(device)\n",
        "        clean_imgs = clean_imgs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(noisy_imgs)\n",
        "        loss = criterion(outputs, clean_imgs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    train_losses.append(avg_loss)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
        "\n",
        "# Plot training loss over epochs\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JdA66dD1lQOP",
        "outputId": "63d60b18-9e80-41b2-b0dc-e471fca0a961"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-aca52ebc06d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Step 6: Train the DnCNN Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 7: Evaluate the Model and Compute PSNR & SSIM\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def denoise_image(model, noisy_img):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        noisy_img = noisy_img.unsqueeze(0).to(device)\n",
        "        denoised = model(noisy_img)\n",
        "    return denoised.squeeze(0).cpu()\n",
        "\n",
        "# Helper function: Convert tensor image to a NumPy array in [0,255] for metric computation\n",
        "def tensor_to_img(tensor_img):\n",
        "    np_img = tensor_img.clamp(0, 1).permute(1, 2, 0).numpy()\n",
        "    np_img = (np_img * 255).astype(np.uint8)\n",
        "    return np_img\n",
        "\n",
        "# Evaluate on a few samples and compute PSNR and SSIM\n",
        "num_eval = 5\n",
        "psnr_list = []\n",
        "ssim_list = []\n",
        "\n",
        "for idx in range(num_eval):\n",
        "    noisy, clean = dataset[idx]\n",
        "    denoised = denoise_image(model, noisy)\n",
        "\n",
        "    noisy_np = tensor_to_img(noisy)\n",
        "    clean_np = tensor_to_img(clean)\n",
        "    denoised_np = tensor_to_img(denoised)\n",
        "\n",
        "    psnr = compare_psnr(clean_np, denoised_np, data_range=255)\n",
        "    ssim = compare_ssim(clean_np, denoised_np, multichannel=True, data_range=255)\n",
        "    psnr_list.append(psnr)\n",
        "    ssim_list.append(ssim)\n",
        "\n",
        "    print(f\"Image {idx+1} - PSNR: {psnr:.2f}, SSIM: {ssim:.4f}\")\n",
        "\n",
        "print(f\"\\nAverage PSNR: {np.mean(psnr_list):.2f}\")\n",
        "print(f\"Average SSIM: {np.mean(ssim_list):.4f}\")\n"
      ],
      "metadata": {
        "id": "czoh8NAhxxLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 8: Visualize Denoising Results\n",
        "num_display = 3\n",
        "plt.figure(figsize=(12, num_display * 4))\n",
        "\n",
        "for i in range(num_display):\n",
        "    noisy, clean = dataset[i]\n",
        "    denoised = denoise_image(model, noisy)\n",
        "\n",
        "    noisy_np = tensor_to_img(noisy)\n",
        "    clean_np = tensor_to_img(clean)\n",
        "    denoised_np = tensor_to_img(denoised)\n",
        "\n",
        "    # Display the images: Noisy, Denoised, Ground Truth\n",
        "    plt.subplot(num_display, 3, i * 3 + 1)\n",
        "    plt.imshow(noisy_np)\n",
        "    plt.title(\"Noisy\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(num_display, 3, i * 3 + 2)\n",
        "    plt.imshow(denoised_np)\n",
        "    plt.title(\"Denoised\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(num_display, 3, i * 3 + 3)\n",
        "    plt.imshow(clean_np)\n",
        "    plt.title(\"Ground Truth\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2B3fvyzklSsu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}