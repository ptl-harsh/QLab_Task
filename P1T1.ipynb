{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ber0cU2CyFQzFPczAtx_viENClwpOYkW",
      "authorship_tag": "ABX9TyNjoqOo3kkBnVEVBwCDFNbG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptl-harsh/QLab_Task/blob/main/P1T1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multivariate Time series Imputation using Transformer Encoder :"
      ],
      "metadata": {
        "id": "AzVpEfKtB2ze"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmd93sLmBr_H",
        "outputId": "a90ffcc8-fd4e-4063-8f5c-f400bf467de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.8)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b01f1599f50>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#@title Step 1: Install and Import Required Libraries\n",
        "\n",
        "# Install wandb if not already installed.\n",
        "!pip install wandb\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import wandb\n",
        "\n",
        "# Set random seeds for reproducibility.\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the CSV file (assuming it's named \"exchange_rate.csv\")\n",
        "data_path = \"/content/iisc-intern-task/exchange_rate.csv\"  # Change this if needed\n",
        "\n",
        "# Read the CSV with comma separator\n",
        "df = pd.read_csv(data_path, sep=\",\")\n",
        "\n",
        "# Print first few rows to check\n",
        "print(\"First few rows:\\n\", df.head())\n",
        "\n",
        "# Convert 'date' column to datetime\n",
        "df['date'] = pd.to_datetime(df['date'], format=\"%Y/%m/%d %H:%M\")\n",
        "\n",
        "# Sort data by date\n",
        "df.sort_values(\"date\", inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Drop the 'date' column and use the rest as features\n",
        "data = df.drop(columns=[\"date\"]).values.astype(np.float32)\n",
        "\n",
        "# Normalize the data (feature-wise)\n",
        "scaler = StandardScaler()\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Processed Data Shape:\", data.shape)\n",
        "print(\"First row (normalized):\", data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjh9__foCZOM",
        "outputId": "079b072c-1716-466c-be74-e809926770a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows:\n",
            "             date       0       1         2         3         4         5  \\\n",
            "0  1990/1/1 0:00  0.7855  1.6110  0.861698  0.634196  0.211242  0.006838   \n",
            "1  1990/1/2 0:00  0.7818  1.6100  0.861104  0.633513  0.211242  0.006863   \n",
            "2  1990/1/3 0:00  0.7867  1.6293  0.861030  0.648508  0.211242  0.006975   \n",
            "3  1990/1/4 0:00  0.7860  1.6370  0.862069  0.650618  0.211242  0.006953   \n",
            "4  1990/1/5 0:00  0.7849  1.6530  0.861995  0.656254  0.211242  0.006940   \n",
            "\n",
            "          6      OT  \n",
            "0  0.525486  0.5930  \n",
            "1  0.523972  0.5940  \n",
            "2  0.526316  0.5973  \n",
            "3  0.523834  0.5970  \n",
            "4  0.527426  0.5985  \n",
            "Processed Data Shape: (7588, 8)\n",
            "First row (normalized): [ 0.06241314 -0.143034    0.3405796  -1.2670058   2.8509977  -1.7183161\n",
            " -1.7407598  -0.5327487 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: Create Dataset for Sequence Generation and Random Masking\n",
        "\n",
        "class TimeSeriesImputationDataset(Dataset):\n",
        "    def __init__(self, data, seq_len=96, mask_ratio=0.25):\n",
        "        \"\"\"\n",
        "        data: numpy array of shape (num_timesteps, num_features)\n",
        "        seq_len: length of each sequence\n",
        "        mask_ratio: fraction of entries to mask randomly in each sequence.\n",
        "        \"\"\"\n",
        "        self.seq_len = seq_len\n",
        "        self.mask_ratio = mask_ratio\n",
        "\n",
        "        # Create overlapping sequences from the data.\n",
        "        self.sequences = []\n",
        "        for i in range(len(data) - seq_len + 1):\n",
        "            self.sequences.append(data[i:i+seq_len])\n",
        "        self.sequences = np.array(self.sequences)  # shape: (num_samples, seq_len, num_features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get original sequence and create a copy for masking.\n",
        "        seq = self.sequences[idx]\n",
        "        # Create a mask for the sequence (True where values are masked)\n",
        "        mask = np.random.rand(*seq.shape) < self.mask_ratio\n",
        "        # Create the input sequence by replacing masked positions with 0.\n",
        "        seq_masked = seq.copy()\n",
        "        seq_masked[mask] = 0.0\n",
        "\n",
        "        # Convert to torch tensors.\n",
        "        seq_masked = torch.tensor(seq_masked, dtype=torch.float32)\n",
        "        seq = torch.tensor(seq, dtype=torch.float32)\n",
        "        mask = torch.tensor(mask, dtype=torch.bool)\n",
        "        return seq_masked, seq, mask\n",
        "\n",
        "# Example: Create a dataset with sequence length 96 and mask ratio of 25%\n",
        "dataset = TimeSeriesImputationDataset(data, seq_len=96, mask_ratio=0.25)\n",
        "print(\"Dataset samples:\", len(dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC8b0C0pDEJE",
        "outputId": "c9da9448-817c-4d72-bb8e-db2ee101cac4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset samples: 7493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 4: Define the Transformer Encoder Imputation Model\n",
        "\n",
        "class TransformerImputer(nn.Module):\n",
        "    def __init__(self, feature_dim, d_model=64, nhead=4, num_layers=2, dropout=0.1):\n",
        "        \"\"\"\n",
        "        feature_dim: number of features in the input.\n",
        "        d_model: embedding dimension.\n",
        "        nhead: number of heads in multi-head attention.\n",
        "        num_layers: number of transformer encoder layers.\n",
        "        \"\"\"\n",
        "        super(TransformerImputer, self).__init__()\n",
        "        self.input_proj = nn.Linear(feature_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_proj = nn.Linear(d_model, feature_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, feature_dim)\n",
        "        x_emb = self.input_proj(x)  # (batch, seq_len, d_model)\n",
        "        # TransformerEncoder (with batch_first=True) accepts (batch, seq_len, d_model)\n",
        "        encoded = self.transformer_encoder(x_emb)\n",
        "        out = self.output_proj(encoded)  # (batch, seq_len, feature_dim)\n",
        "        return out\n",
        "\n",
        "# Initialize model\n",
        "feature_dim = data.shape[1]\n",
        "model = TransformerImputer(feature_dim=feature_dim, d_model=64, nhead=4, num_layers=2, dropout=0.1)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkqNkgsPE8C7",
        "outputId": "7d873d46-2efe-43c6-f429-d9c1517eca37"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerImputer(\n",
            "  (input_proj): Linear(in_features=8, out_features=64, bias=True)\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
            "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (output_proj): Linear(in_features=64, out_features=8, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 5: Define Training and Evaluation Functions\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for seq_masked, seq_orig, mask in dataloader:\n",
        "        seq_masked = seq_masked.to(device)\n",
        "        seq_orig = seq_orig.to(device)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(seq_masked)\n",
        "        # Calculate loss only for the masked positions.\n",
        "        loss = criterion(output[mask], seq_orig[mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_mae = 0.0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for seq_masked, seq_orig, mask in dataloader:\n",
        "            seq_masked = seq_masked.to(device)\n",
        "            seq_orig = seq_orig.to(device)\n",
        "            mask = mask.to(device)\n",
        "\n",
        "            output = model(seq_masked)\n",
        "            mse_loss = criterion(output[mask], seq_orig[mask]).item()\n",
        "            mae_loss = nn.L1Loss()(output[mask], seq_orig[mask]).item()\n",
        "            total_loss += mse_loss\n",
        "            total_mae += mae_loss\n",
        "            count += 1\n",
        "    return total_loss / count, total_mae / count\n"
      ],
      "metadata": {
        "id": "WXdiIR7CFBS2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 6: Train the Model for Different Mask Ratios using Weights & Biases\n",
        "\n",
        "# Define training hyperparameters.\n",
        "num_epochs = 10       # Adjust epochs as needed.\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# List of mask ratios to try.\n",
        "mask_ratios = [0.125, 0.25, 0.375, 0.5]\n",
        "\n",
        "# Dictionary to store evaluation results for visualization.\n",
        "results = {}\n",
        "\n",
        "for ratio in mask_ratios:\n",
        "    print(f\"\\nTraining for mask ratio: {ratio}\")\n",
        "\n",
        "    # Initialize a new wandb run for each mask ratio.\n",
        "    wandb.init(project=\"QLabIntern2025_Imputation\",\n",
        "               name=f\"Transformer_Imputation_mask_{int(ratio*100)}\",\n",
        "               config={\"mask_ratio\": ratio, \"epochs\": num_epochs, \"batch_size\": batch_size, \"learning_rate\": learning_rate})\n",
        "\n",
        "    # Create dataset and dataloaders for current mask ratio.\n",
        "    train_dataset = TimeSeriesImputationDataset(data, seq_len=96, mask_ratio=ratio)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)  # For simplicity, using same data for validation\n",
        "\n",
        "    # Initialize model (fresh for each ratio) and optimizer.\n",
        "    model = TransformerImputer(feature_dim=feature_dim, d_model=64, nhead=4, num_layers=2, dropout=0.1).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    epoch_losses = []\n",
        "    epoch_mae = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_mse, val_mae = evaluate(model, val_loader, criterion, device)\n",
        "        epoch_losses.append(val_mse)\n",
        "        epoch_mae.append(val_mae)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Val MSE: {val_mse:.4f}, Val MAE: {val_mae:.4f}\")\n",
        "\n",
        "        # Log metrics to wandb.\n",
        "        wandb.log({\"epoch\": epoch+1, \"Val_MSE\": val_mse, \"Val_MAE\": val_mae})\n",
        "\n",
        "    # Save results for visualization later.\n",
        "    results[ratio] = {\"mse\": epoch_losses, \"mae\": epoch_mae}\n",
        "\n",
        "    # Optionally, save the model checkpoint.\n",
        "    wandb.save(\"model.pt\")\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cycanR22FFWd",
        "outputId": "5b7441ef-e822-4e7c-9055-0f25ef365bcd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Training for mask ratio: 0.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhvpatel-me\u001b[0m (\u001b[33mhvpatel-me-nit-patna\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250320_102641-kettab5b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/kettab5b' target=\"_blank\">Transformer_Imputation_mask_12</a></strong> to <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/kettab5b' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/kettab5b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Val MSE: 0.0280, Val MAE: 0.1216\n",
            "Epoch 2/10 - Val MSE: 0.0214, Val MAE: 0.1024\n",
            "Epoch 3/10 - Val MSE: 0.0196, Val MAE: 0.0983\n",
            "Epoch 4/10 - Val MSE: 0.0165, Val MAE: 0.0896\n",
            "Epoch 5/10 - Val MSE: 0.0158, Val MAE: 0.0876\n",
            "Epoch 6/10 - Val MSE: 0.0156, Val MAE: 0.0887\n",
            "Epoch 7/10 - Val MSE: 0.0143, Val MAE: 0.0830\n",
            "Epoch 8/10 - Val MSE: 0.0144, Val MAE: 0.0852\n",
            "Epoch 9/10 - Val MSE: 0.0131, Val MAE: 0.0810\n",
            "Epoch 10/10 - Val MSE: 0.0119, Val MAE: 0.0769\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_MAE</td><td>█▅▄▃▃▃▂▂▂▁</td></tr><tr><td>Val_MSE</td><td>█▅▄▃▃▃▂▂▂▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_MAE</td><td>0.07694</td></tr><tr><td>Val_MSE</td><td>0.01191</td></tr><tr><td>epoch</td><td>10</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Transformer_Imputation_mask_12</strong> at: <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/kettab5b' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/kettab5b</a><br> View project at: <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250320_102641-kettab5b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training for mask ratio: 0.25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250320_105934-euxd3awe</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/euxd3awe' target=\"_blank\">Transformer_Imputation_mask_25</a></strong> to <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/euxd3awe' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/euxd3awe</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Val MSE: 0.0288, Val MAE: 0.1205\n",
            "Epoch 2/10 - Val MSE: 0.0233, Val MAE: 0.1070\n",
            "Epoch 3/10 - Val MSE: 0.0218, Val MAE: 0.1040\n",
            "Epoch 4/10 - Val MSE: 0.0216, Val MAE: 0.1061\n",
            "Epoch 5/10 - Val MSE: 0.0180, Val MAE: 0.0936\n",
            "Epoch 6/10 - Val MSE: 0.0178, Val MAE: 0.0933\n",
            "Epoch 7/10 - Val MSE: 0.0173, Val MAE: 0.0941\n",
            "Epoch 8/10 - Val MSE: 0.0145, Val MAE: 0.0833\n",
            "Epoch 9/10 - Val MSE: 0.0138, Val MAE: 0.0818\n",
            "Epoch 10/10 - Val MSE: 0.0151, Val MAE: 0.0864\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_MAE</td><td>█▆▅▅▃▃▃▁▁▂</td></tr><tr><td>Val_MSE</td><td>█▅▅▅▃▃▃▁▁▂</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_MAE</td><td>0.08635</td></tr><tr><td>Val_MSE</td><td>0.01506</td></tr><tr><td>epoch</td><td>10</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Transformer_Imputation_mask_25</strong> at: <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/euxd3awe' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/euxd3awe</a><br> View project at: <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250320_105934-euxd3awe/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training for mask ratio: 0.375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250320_113320-wmkl5zra</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/wmkl5zra' target=\"_blank\">Transformer_Imputation_mask_37</a></strong> to <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/wmkl5zra' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/wmkl5zra</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Val MSE: 0.0307, Val MAE: 0.1256\n",
            "Epoch 2/10 - Val MSE: 0.0265, Val MAE: 0.1153\n",
            "Epoch 3/10 - Val MSE: 0.0231, Val MAE: 0.1063\n",
            "Epoch 4/10 - Val MSE: 0.0244, Val MAE: 0.1101\n",
            "Epoch 5/10 - Val MSE: 0.0203, Val MAE: 0.0989\n",
            "Epoch 6/10 - Val MSE: 0.0228, Val MAE: 0.1081\n",
            "Epoch 7/10 - Val MSE: 0.0188, Val MAE: 0.0958\n",
            "Epoch 8/10 - Val MSE: 0.0176, Val MAE: 0.0915\n",
            "Epoch 9/10 - Val MSE: 0.0168, Val MAE: 0.0895\n",
            "Epoch 10/10 - Val MSE: 0.0168, Val MAE: 0.0901\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_MAE</td><td>█▆▄▅▃▅▂▁▁▁</td></tr><tr><td>Val_MSE</td><td>█▆▄▅▃▄▂▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_MAE</td><td>0.09014</td></tr><tr><td>Val_MSE</td><td>0.01679</td></tr><tr><td>epoch</td><td>10</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Transformer_Imputation_mask_37</strong> at: <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/wmkl5zra' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/wmkl5zra</a><br> View project at: <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250320_113320-wmkl5zra/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training for mask ratio: 0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250320_120615-tlq9er6r</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/tlq9er6r' target=\"_blank\">Transformer_Imputation_mask_50</a></strong> to <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/tlq9er6r' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/tlq9er6r</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Val MSE: 0.0358, Val MAE: 0.1377\n",
            "Epoch 2/10 - Val MSE: 0.0336, Val MAE: 0.1321\n",
            "Epoch 3/10 - Val MSE: 0.0277, Val MAE: 0.1172\n",
            "Epoch 4/10 - Val MSE: 0.0252, Val MAE: 0.1109\n",
            "Epoch 5/10 - Val MSE: 0.0226, Val MAE: 0.1044\n",
            "Epoch 6/10 - Val MSE: 0.0214, Val MAE: 0.1013\n",
            "Epoch 7/10 - Val MSE: 0.0208, Val MAE: 0.1003\n",
            "Epoch 8/10 - Val MSE: 0.0198, Val MAE: 0.0973\n",
            "Epoch 9/10 - Val MSE: 0.0198, Val MAE: 0.0973\n",
            "Epoch 10/10 - Val MSE: 0.0216, Val MAE: 0.1031\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_MAE</td><td>█▇▄▃▂▂▂▁▁▂</td></tr><tr><td>Val_MSE</td><td>█▇▄▃▂▂▁▁▁▂</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_MAE</td><td>0.10309</td></tr><tr><td>Val_MSE</td><td>0.02156</td></tr><tr><td>epoch</td><td>10</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Transformer_Imputation_mask_50</strong> at: <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/tlq9er6r' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation/runs/tlq9er6r</a><br> View project at: <a href='https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation' target=\"_blank\">https://wandb.ai/hvpatel-me-nit-patna/QLabIntern2025_Imputation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250320_120615-tlq9er6r/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}