{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsm16FFR1EJx8DgPFIumeR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptl-harsh/QLab_Task/blob/main/P2T2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Denoising using Unet architecture"
      ],
      "metadata": {
        "id": "ChI0IqgJqZ5p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3w95NhvqXA3",
        "outputId": "6e0d61cf-6b93-4f93-b59b-da594bad406d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.13)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Step 1: Mount Google Drive and Install Required Libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install torch torchvision torchaudio scikit-image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2: Import Libraries and Set Up Environment\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from PIL import Image\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n"
      ],
      "metadata": {
        "id": "Zp2HKzb_sMzZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: Define the Dataset for CBSD68 (Using \"original_png\" for clean images)\n",
        "base_dir = \"/content/drive/MyDrive/IISC_intern_task/CBSD68\"  # Update if needed\n",
        "\n",
        "noisy_dir = os.path.join(base_dir, \"noisy35\")\n",
        "clean_dir = os.path.join(base_dir, \"original_png\")\n",
        "\n",
        "class CBSD68Dataset(Dataset):\n",
        "    def __init__(self, noisy_dir, clean_dir, transform=None):\n",
        "        self.noisy_paths = sorted(glob.glob(os.path.join(noisy_dir, \"*.png\")))\n",
        "        self.clean_paths = sorted(glob.glob(os.path.join(clean_dir, \"*.png\")))\n",
        "        self.transform = transform\n",
        "\n",
        "        if len(self.noisy_paths) == 0 or len(self.clean_paths) == 0:\n",
        "            raise ValueError(\"No images found. Check your directory paths and file extensions.\")\n",
        "        if len(self.noisy_paths) != len(self.clean_paths):\n",
        "            raise ValueError(\"Mismatch in number of noisy and clean images.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy_img = Image.open(self.noisy_paths[idx]).convert(\"RGB\")\n",
        "        clean_img = Image.open(self.clean_paths[idx]).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            noisy = self.transform(noisy_img)\n",
        "            clean = self.transform(clean_img)\n",
        "        else:\n",
        "            to_tensor = transforms.ToTensor()\n",
        "            noisy = to_tensor(noisy_img)\n",
        "            clean = to_tensor(clean_img)\n",
        "\n",
        "        return noisy, clean\n",
        "\n",
        "# Define a transform: Resize images to 256x256 and convert to tensor.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),  # Converts image to tensor with values in [0,1]\n",
        "])\n",
        "\n",
        "dataset = CBSD68Dataset(noisy_dir, clean_dir, transform=transform)\n",
        "print(\"Number of image pairs:\", len(dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhicYV4Bs0wE",
        "outputId": "f92f2f96-59d8-4d9a-b8ce-47e442ed0b81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of image pairs: 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 4: Define the U-Net Model for Image Denoising\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, features=[64, 128, 256, 512]):\n",
        "        super(UNet, self).__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Downward part\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Upward part\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)  # upsample\n",
        "            skip_connection = skip_connections[idx//2]\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = torch.nn.functional.interpolate(x, size=skip_connection.shape[2:])\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# Initialize the U-Net model\n",
        "model = UNet(in_channels=3, out_channels=3)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7xZe0rstDpA",
        "outputId": "d822d647-afaa-4da1-ed7b-fdaa397a6fec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet(\n",
            "  (downs): ModuleList(\n",
            "    (0): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (1): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (2): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (3): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ups): ModuleList(\n",
            "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (1): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (3): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (5): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (7): DoubleConv(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (bottleneck): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 5: Set Up Training Parameters and DataLoader\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "dq1gWFaQtLEy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 6: Train the U-Net Model\n",
        "model.train()\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    for noisy_imgs, clean_imgs in dataloader:\n",
        "        noisy_imgs = noisy_imgs.to(device)\n",
        "        clean_imgs = clean_imgs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(noisy_imgs)\n",
        "        loss = criterion(outputs, clean_imgs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    train_losses.append(avg_loss)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "54Epq4A1tS1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 7: Evaluate the Model and Compute PSNR & SSIM\n",
        "def denoise_image(model, noisy_img):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        noisy_img = noisy_img.unsqueeze(0).to(device)\n",
        "        denoised = model(noisy_img)\n",
        "    return denoised.squeeze(0).cpu()\n",
        "\n",
        "# Helper function: Convert tensor image to a NumPy image in [0,255]\n",
        "def tensor_to_img(tensor_img):\n",
        "    np_img = tensor_img.clamp(0, 1).permute(1, 2, 0).numpy()\n",
        "    np_img = (np_img * 255).astype(np.uint8)\n",
        "    return np_img\n",
        "\n",
        "num_eval = 5\n",
        "psnr_list = []\n",
        "ssim_list = []\n",
        "\n",
        "for idx in range(num_eval):\n",
        "    noisy, clean = dataset[idx]\n",
        "    denoised = denoise_image(model, noisy)\n",
        "\n",
        "    noisy_np = tensor_to_img(noisy)\n",
        "    clean_np = tensor_to_img(clean)\n",
        "    denoised_np = tensor_to_img(denoised)\n",
        "\n",
        "    psnr = compare_psnr(clean_np, denoised_np, data_range=255)\n",
        "    ssim = compare_ssim(clean_np, denoised_np, multichannel=True, data_range=255)\n",
        "    psnr_list.append(psnr)\n",
        "    ssim_list.append(ssim)\n",
        "\n",
        "    print(f\"Image {idx+1} - PSNR: {psnr:.2f}, SSIM: {ssim:.4f}\")\n",
        "\n",
        "print(f\"\\nAverage PSNR: {np.mean(psnr_list):.2f}\")\n",
        "print(f\"Average SSIM: {np.mean(ssim_list):.4f}\")\n"
      ],
      "metadata": {
        "id": "mOPkgs1UtZ5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 8: Visualize Denoising Results\n",
        "num_display = 3\n",
        "plt.figure(figsize=(12, num_display * 4))\n",
        "\n",
        "for i in range(num_display):\n",
        "    noisy, clean = dataset[i]\n",
        "    denoised = denoise_image(model, noisy)\n",
        "\n",
        "    noisy_np = tensor_to_img(noisy)\n",
        "    clean_np = tensor_to_img(clean)\n",
        "    denoised_np = tensor_to_img(denoised)\n",
        "\n",
        "    # Display images: Noisy, Denoised, Ground Truth\n",
        "    plt.subplot(num_display, 3, i * 3 + 1)\n",
        "    plt.imshow(noisy_np)\n",
        "    plt.title(\"Noisy\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(num_display, 3, i * 3 + 2)\n",
        "    plt.imshow(denoised_np)\n",
        "    plt.title(\"Denoised\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(num_display, 3, i * 3 + 3)\n",
        "    plt.imshow(clean_np)\n",
        "    plt.title(\"Ground Truth\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wpP_O7f3xUue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lc4OFTRTxavs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}